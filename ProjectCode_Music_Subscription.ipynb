{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "df = spark.read.csv(\"HW4 - training data.csv\", header=True, inferSchema=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- male: double (nullable = true)\n",
      " |-- friend_cnt: double (nullable = true)\n",
      " |-- avg_friend_age: double (nullable = true)\n",
      " |-- avg_friend_male: double (nullable = true)\n",
      " |-- friend_country_cnt: double (nullable = true)\n",
      " |-- subscriber_friend_cnt: double (nullable = true)\n",
      " |-- songsListened: double (nullable = true)\n",
      " |-- lovedTracks: double (nullable = true)\n",
      " |-- posts: double (nullable = true)\n",
      " |-- playlists: double (nullable = true)\n",
      " |-- shouts: double (nullable = true)\n",
      " |-- delta_friend_cnt: double (nullable = true)\n",
      " |-- delta_avg_friend_age: double (nullable = true)\n",
      " |-- delta_avg_friend_male: double (nullable = true)\n",
      " |-- delta_friend_country_cnt: double (nullable = true)\n",
      " |-- delta_subscriber_friend_cnt: double (nullable = true)\n",
      " |-- delta_songsListened: double (nullable = true)\n",
      " |-- delta_lovedTracks: double (nullable = true)\n",
      " |-- delta_posts: double (nullable = true)\n",
      " |-- delta_playlists: double (nullable = true)\n",
      " |-- delta_shouts: double (nullable = true)\n",
      " |-- tenure: double (nullable = true)\n",
      " |-- good_country: double (nullable = true)\n",
      " |-- delta_good_country: double (nullable = true)\n",
      " |-- adopter: integer (nullable = true)\n",
      " |-- user_id: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+--------------+---------------+------------------+---------------------+-------------+-----------+-----+---------+------+----------------+--------------------+---------------------+------------------------+---------------------------+-------------------+-----------------+-----------+---------------+------------+------+------------+------------------+-------+-------+\n",
      "| age|male|friend_cnt|avg_friend_age|avg_friend_male|friend_country_cnt|subscriber_friend_cnt|songsListened|lovedTracks|posts|playlists|shouts|delta_friend_cnt|delta_avg_friend_age|delta_avg_friend_male|delta_friend_country_cnt|delta_subscriber_friend_cnt|delta_songsListened|delta_lovedTracks|delta_posts|delta_playlists|delta_shouts|tenure|good_country|delta_good_country|adopter|user_id|\n",
      "+----+----+----------+--------------+---------------+------------------+---------------------+-------------+-----------+-----+---------+------+----------------+--------------------+---------------------+------------------------+---------------------------+-------------------+-----------------+-----------+---------------+------------+------+------------+------------------+-------+-------+\n",
      "|24.0| 0.0|      20.0|  26.333333333|   0.7777777778|               6.0|                  0.0|      37804.0|        4.0| 20.0|      1.0|  47.0|             0.0|        0.2222222222|                  0.0|                     0.0|                        0.0|               54.0|              0.0|        0.0|            0.0|         0.0|  79.0|         0.0|               0.0|      0|   10.0|\n",
      "|29.0| 1.0|      12.0|          26.9|   0.8181818182|               6.0|                  1.0|      15955.0|       19.0|  4.0|      0.0|   8.0|             0.0|                 0.5|                  0.0|                     0.0|                        0.0|              802.0|              0.0|        0.0|            0.0|         1.0|  80.0|         0.0|               0.0|      0|   58.0|\n",
      "|22.0| 0.0|       4.0|          21.0|            1.0|               2.0|                  0.0|      31441.0|        7.0|  0.0|      0.0|   4.0|             0.0|                 0.0|                  0.0|                     0.0|                        0.0|                0.0|              0.0|        0.0|            0.0|         0.0|  53.0|         0.0|               0.0|      0|   72.0|\n",
      "|27.0| 0.0|       1.0|          29.0|            1.0|               1.0|                  0.0|          0.0|        0.0|  0.0|      1.0|   1.0|             0.0|                 0.0|                  0.0|                     0.0|                        0.0|                0.0|              0.0|        0.0|            0.0|         0.0|  59.0|         0.0|               0.0|      0|  121.0|\n",
      "|22.0| 1.0|       4.0|         21.25|           0.75|               1.0|                  0.0|        774.0|        0.0|  0.0|      0.0|   3.0|             0.0|                 1.0|                  0.0|                     0.0|                        0.0|                0.0|              0.0|        0.0|            0.0|         0.0|  60.0|         0.0|               0.0|      0|  137.0|\n",
      "+----+----+----------+--------------+---------------+------------------+---------------------+-------------+-----------+-----+---------+------+----------------+--------------------+---------------------+------------------------+---------------------------+-------------------+-----------------+-----------+---------------+------------+------+------------+------------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------------------+\n",
      "|adopter|count|          Proportion|\n",
      "+-------+-----+--------------------+\n",
      "|      1| 1540|0.017766087538358597|\n",
      "|      0|85142|  0.9822339124616414|\n",
      "+-------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the proportion of each class\n",
    "class_cnt = df.groupBy('adopter').count()\n",
    "total_cnt = df.count()\n",
    "class_cnt.withColumn('Proportion', class_cnt['Count']/total_cnt).show()\n",
    "# Super imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-------------------+\n",
      "|adopter|count|         Proportion|\n",
      "+-------+-----+-------------------+\n",
      "|      0|85142| 0.7489158830824985|\n",
      "|      1|28545|0.25108411691750154|\n",
      "+-------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Firstly deal with the imbalanced dataset\n",
    "from pyspark.sql.functions import col\n",
    "df_major = df.filter(col('adopter') == 0)\n",
    "df_minor = df.filter(col('adopter') == 1)\n",
    "cnt_major = df_major.count()\n",
    "cnt_minor = df_minor.count()\n",
    "\n",
    "# Oversample the minor class, but not to 1:1; oversample to 1:3\n",
    "df_minor_oversampled = df_minor.sample(True, cnt_major/(cnt_minor*3), seed = 42)\n",
    "df_balanced = df_major.union(df_minor_oversampled)\n",
    "\n",
    "# Check the distribution again\n",
    "class_cnt = df_balanced.groupBy('adopter').count()\n",
    "total_cnt = df_balanced.count()\n",
    "class_cnt.withColumn('Proportion', class_cnt['Count']/total_cnt).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the original df\n",
    "df = df_balanced\n",
    "# Drop the user id\n",
    "df = df.drop('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "df_train, df_test = df.randomSplit([0.7, 0.3], seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an assembler\n",
    "features = [col for col in df.columns if col != \"adopter\"]\n",
    "assembler = VectorAssembler(inputCols = features, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler\n",
    "scaler = StandardScaler(inputCol = \"features\", outputCol = \"scaled_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator: f1\n",
    "f1 = MulticlassClassificationEvaluator(labelCol=\"adopter\", predictionCol=\"prediction\", metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1. Decision Tree\n",
    "dt = DecisionTreeClassifier(featuresCol = \"scaled_features\", labelCol = \"adopter\", seed = 42)\n",
    "pl_dt = Pipeline(stages = [assembler, scaler, dt])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [3, 5, 10]) \\\n",
    "    .addGrid(dt.minInstancesPerNode, [5, 10, 20]) \\\n",
    "    .addGrid(dt.impurity, ['gini', 'entropy']) \\\n",
    "    .build()\n",
    "cv = CrossValidator(estimator = pl_dt, estimatorParamMaps = paramGrid, evaluator = f1, numFolds = 3, seed = 42)\n",
    "cv_model = cv.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_89a2322d6839, depth=10, numNodes=787, numClasses=2, numFeatures=25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best = cv_model.bestModel\n",
    "dt_best.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8415140584946538"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = dt_best.transform(df_test)\n",
    "f1_dt = f1.evaluate(pred)\n",
    "f1_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Max Depth: 10\n",
      "Best Min Instances Per Node: 5\n",
      "Best Impurity: gini\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Max Depth: {dt_best.stages[-1].getMaxDepth()}\")\n",
    "print(f\"Best Min Instances Per Node: {dt_best.stages[-1].getMinInstancesPerNode()}\")\n",
    "print(f\"Best Impurity: {dt_best.stages[-1].getImpurity()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2. Random Forest\n",
    "rf = RandomForestClassifier(featuresCol = \"scaled_features\", labelCol = \"adopter\", seed = 42)\n",
    "pl_rf = Pipeline(stages = [assembler, scaler, rf])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 200]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 20]) \\\n",
    "    .addGrid(rf.minInstancesPerNode, [5, 10]) \\\n",
    "    .build()\n",
    "cv = CrossValidator(estimator = pl_rf, estimatorParamMaps = paramGrid, evaluator = f1, numFolds = 3, seed = 42)\n",
    "cv_model = cv.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_eff2b40387b9, depth=5, numNodes=41, numClasses=2, numFeatures=25"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best = cv_model.bestModel\n",
    "rf_best.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573694324732099"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = rf_best.transform(df_test)\n",
    "f1_rf = f1.evaluate(pred)\n",
    "f1_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3. GBT\n",
    "gbt = GBTClassifier(featuresCol = \"scaled_features\", labelCol = \"adopter\", seed = 42)\n",
    "pl_gbt = Pipeline(stages = [assembler, scaler, gbt])\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10, 20]) \\\n",
    "    .addGrid(gbt.minInstancesPerNode, [1, 5]) \\\n",
    "    .addGrid(gbt.stepSize, [0.1, 0.3, 0.5]) \\\n",
    "    .build()\n",
    "cv = CrossValidator(estimator = pl_gbt, estimatorParamMaps = paramGrid, evaluator = f1, numFolds = 3, seed = 42)\n",
    "cv_model = cv.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_best = cv_model.bestModel\n",
    "gbt_best.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbt_best.transform(df_test)\n",
    "precision_gbt = f1.evaluate(pred)\n",
    "precision_gbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4. Logistic Regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"adopter\")\n",
    "\n",
    "class ProbabilityThreshold(Transformer, Params):\n",
    "    threshold = Param(Params._dummy(), \"threshold\", \"threshold for binary classification\")\n",
    "    outputCol = Param(Params._dummy(), \"outputCol\", \"output column name\")\n",
    "\n",
    "    def __init__(self, threshold=0.3, outputCol=\"custom_prediction\"):\n",
    "        super(ProbabilityThreshold, self).__init__()\n",
    "        self._set(threshold=threshold, outputCol=outputCol)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        threshold = self.getThreshold()\n",
    "        \n",
    "        def apply_threshold(probability):\n",
    "            return float(probability[1] > threshold)\n",
    "\n",
    "        apply_threshold_udf = udf(apply_threshold, DoubleType())\n",
    "        return dataset.withColumn(self.getOutputCol(), apply_threshold_udf(dataset.probability))\n",
    "\n",
    "    def getThreshold(self):\n",
    "        return self.getOrDefault(self.threshold)\n",
    "\n",
    "    def setThreshold(self, value):\n",
    "        return self._set(threshold=value)\n",
    "\n",
    "    def getOutputCol(self):\n",
    "        return self.getOrDefault(self.outputCol)\n",
    "\n",
    "    def setOutputCol(self, value):\n",
    "        return self._set(outputCol=value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the custom transformer to the pipeline\n",
    "th = ProbabilityThreshold(threshold=0.3, outputCol=\"custom_prediction\")\n",
    "\n",
    "pl_lr = Pipeline(stages=[assembler, scaler, lr, th])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilityThreshold_cebf95b4701d"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CrossValidator(estimator=pl_lr, estimatorParamMaps=paramGrid, evaluator=f1, numFolds=3, seed=42)\n",
    "\n",
    "cv_model = cv.fit(df_train)\n",
    "lr_best = cv_model.bestModel\n",
    "lr_best.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7099224185317523"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lr_best.transform(df_test)\n",
    "f1_lr = f1.evaluate(pred)\n",
    "f1_lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.csv(\"HW4 - test data.csv\", header=True, inferSchema=True, sep=';')\n",
    "user_id = df2.select(\"user_id\")\n",
    "df2 = df2.drop('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = DecisionTreeClassifier(featuresCol = \"scaled_features\", labelCol = \"adopter\", seed = 42, maxDepth = 10, minInstancesPerNode = 5, impurity = \"gini\")\n",
    "pl = Pipeline(stages = [assembler, scaler, best])\n",
    "model = lr.fit(df_train)\n",
    "pred = model.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prediction = pred.select('prediction').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prediction(adopter)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  prediction(adopter)\n",
       "0        5                False\n",
       "1       41                False\n",
       "2       77                False\n",
       "3       99                False\n",
       "4      106                 True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "result = pd.read_csv('result2.csv')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = user_id.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([user_id, prediction], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns={'prediction': 'prediction(adopter)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['user_id'] = result['user_id'].astype(str)\n",
    "result['prediction(adopter)'] = result['prediction(adopter)'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prediction(adopter)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86676</th>\n",
       "      <td>1708912</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86677</th>\n",
       "      <td>1708924</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86678</th>\n",
       "      <td>1708946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86679</th>\n",
       "      <td>1708972</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86680</th>\n",
       "      <td>1708981</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  prediction(adopter)\n",
       "0            5                False\n",
       "1           41                False\n",
       "2           77                False\n",
       "3           99                False\n",
       "4          106                 True\n",
       "...        ...                  ...\n",
       "86676  1708912                False\n",
       "86677  1708924                False\n",
       "86678  1708946                False\n",
       "86679  1708972                False\n",
       "86680  1708981                False\n",
       "\n",
       "[86681 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                object\n",
       "prediction(adopter)      bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('result2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['user_id'] = result['user_id'].astype(float)\n",
    "result['prediction(adopter)'] = result['prediction(adopter)'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                float64\n",
       "prediction(adopter)       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prediction(adopter)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>106.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86676</th>\n",
       "      <td>1708912.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86677</th>\n",
       "      <td>1708924.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86678</th>\n",
       "      <td>1708946.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86679</th>\n",
       "      <td>1708972.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86680</th>\n",
       "      <td>1708981.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  prediction(adopter)\n",
       "0            5.0                False\n",
       "1           41.0                 True\n",
       "2           77.0                 True\n",
       "3           99.0                 True\n",
       "4          106.0                 True\n",
       "...          ...                  ...\n",
       "86676  1708912.0                 True\n",
       "86677  1708924.0                False\n",
       "86678  1708946.0                 True\n",
       "86679  1708972.0                 True\n",
       "86680  1708981.0                False\n",
       "\n",
       "[86681 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('result4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('result4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                float64\n",
       "prediction(adopter)       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
